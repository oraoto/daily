---
title: "2018-04-17"
date: 2018-04-17T13:33:57+08:00
---

# 看了

+ [Go: the Good, the Bad and the Ugly](https://bluxte.net/musings/2018/04/10/go-good-bad-ugly/)

    Go的优缺点

+ [Learning to Learn](http://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/)

    Meta-leaning常用的方法：循环模型、度量学习、优化器学习，MAML算法直接学习参数的初始值，学到的值有很好的泛化性能，对输入敏感，learner只需少量样本就可以调优。

+ [Is sorted using SIMD instructions](http://0x80.pl/notesen/2018-04-11-simd-is-sorted.html)

    用SIMD实现is_sorted，AVX2有两倍以上提速，基本思路是把数组错一位复制到两个vector，然后SIMD比较两个vecotr对应数字大小，结果不全为0就是没排序的。

    SSE：两次`_mm_loadu_si128`、一次`_mm_cmpgt_epi32`、一次`_mm_test_all_zeros`，通过`_mm_palignr_epi8`减少读反而更慢了。

    GCC -O3能生成[类似的结果](https://news.ycombinator.com/item?id=16842426)，但没有early return。

+ [What are control and prediction mean in reinforcement learning?](https://www.quora.com/What-are-control-and-prediction-mean-in-reinforcement-learning)

    预测和控制是RL的基本任务。Model free的RL通过`Q(状态，行动)`来进行预测，控制就是找到某状态下Q函数最大的动作，这就需要遍历全部可能的动作。根据反例得到Imagination values可以减少可行的行动。

+ [机器人学习最前沿：一眼模仿学习（One-Shot Imitation Learning）的三级跳](https://zhuanlan.zhihu.com/p/33789604)

    One-Shot Imitation Learning，MAML算法。

